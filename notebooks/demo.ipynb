{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/lightning_lite/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "import biotite.structure.io as bsio\n",
    "\n",
    "from proteinttt.models.esm2 import ESM2TTT, DEFAULT_ESM2_35M_TTT_CFG\n",
    "from proteinttt.models.esmfold import ESMFoldTTT, DEFAULT_ESMFOLD_TTT_CFG\n",
    "from proteinttt.base import TTTConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESM2\n",
    "\n",
    "Adaptation of an official [ESM2 example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/torch/hub.py:338: UserWarning: TORCH_HUB is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_HUB is deprecated, please use env TORCH_HOME instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 15:33:14,661 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 0.00001\n",
      "2025-11-04 15:33:15,400 | INFO | step: 1, accumulated_step: 16, loss: 0.75260, perplexity: None, ttt_step_time: 0.73787, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:15,831 | INFO | step: 2, accumulated_step: 32, loss: 0.73837, perplexity: None, ttt_step_time: 0.43010, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:16,262 | INFO | step: 3, accumulated_step: 48, loss: 0.68426, perplexity: None, ttt_step_time: 0.43029, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:16,692 | INFO | step: 4, accumulated_step: 64, loss: 0.69365, perplexity: None, ttt_step_time: 0.42923, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,117 | INFO | step: 5, accumulated_step: 80, loss: 0.67766, perplexity: None, ttt_step_time: 0.42461, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,520 | INFO | step: 6, accumulated_step: 96, loss: 0.70075, perplexity: None, ttt_step_time: 0.40306, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,923 | INFO | step: 7, accumulated_step: 112, loss: 0.65884, perplexity: None, ttt_step_time: 0.40221, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:18,326 | INFO | step: 8, accumulated_step: 128, loss: 0.66001, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:18,729 | INFO | step: 9, accumulated_step: 144, loss: 0.64459, perplexity: None, ttt_step_time: 0.40210, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,131 | INFO | step: 10, accumulated_step: 160, loss: 0.64300, perplexity: None, ttt_step_time: 0.40212, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,534 | INFO | step: 11, accumulated_step: 176, loss: 0.63965, perplexity: None, ttt_step_time: 0.40232, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,937 | INFO | step: 12, accumulated_step: 192, loss: 0.58372, perplexity: None, ttt_step_time: 0.40196, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:20,340 | INFO | step: 13, accumulated_step: 208, loss: 0.61558, perplexity: None, ttt_step_time: 0.40238, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:20,742 | INFO | step: 14, accumulated_step: 224, loss: 0.61332, perplexity: None, ttt_step_time: 0.40196, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,145 | INFO | step: 15, accumulated_step: 240, loss: 0.60931, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,548 | INFO | step: 16, accumulated_step: 256, loss: 0.63115, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,950 | INFO | step: 17, accumulated_step: 272, loss: 0.56141, perplexity: None, ttt_step_time: 0.40182, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:22,353 | INFO | step: 18, accumulated_step: 288, loss: 0.56737, perplexity: None, ttt_step_time: 0.40264, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:22,756 | INFO | step: 19, accumulated_step: 304, loss: 0.59121, perplexity: None, ttt_step_time: 0.40208, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,159 | INFO | step: 20, accumulated_step: 320, loss: 0.54132, perplexity: None, ttt_step_time: 0.40199, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,562 | INFO | step: 21, accumulated_step: 336, loss: 0.52530, perplexity: None, ttt_step_time: 0.40292, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,966 | INFO | step: 22, accumulated_step: 352, loss: 0.56913, perplexity: None, ttt_step_time: 0.40299, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:24,368 | INFO | step: 23, accumulated_step: 368, loss: 0.49984, perplexity: None, ttt_step_time: 0.40215, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:24,771 | INFO | step: 24, accumulated_step: 384, loss: 0.52193, perplexity: None, ttt_step_time: 0.40208, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,174 | INFO | step: 25, accumulated_step: 400, loss: 0.50582, perplexity: None, ttt_step_time: 0.40207, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,577 | INFO | step: 26, accumulated_step: 416, loss: 0.51759, perplexity: None, ttt_step_time: 0.40236, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,979 | INFO | step: 27, accumulated_step: 432, loss: 0.50721, perplexity: None, ttt_step_time: 0.40210, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:26,382 | INFO | step: 28, accumulated_step: 448, loss: 0.48393, perplexity: None, ttt_step_time: 0.40220, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:26,785 | INFO | step: 29, accumulated_step: 464, loss: 0.50045, perplexity: None, ttt_step_time: 0.40203, score_seq_time: 0.00000, eval_step_time: 0.00006\n",
      "2025-11-04 15:33:27,187 | INFO | step: 30, accumulated_step: 480, loss: 0.50168, perplexity: None, ttt_step_time: 0.40222, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "torch.Size([480])\n"
     ]
    }
   ],
   "source": [
    "seq = \"HRQALGERLYPRVQAMQPAFASKITGMLLELSPAQLLLLLASEDSLRARVDEAMELII\"\n",
    "\n",
    "# Load ESM-2 model and data\n",
    "model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval().to(device)  # disables dropout for deterministic results\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter([(None, seq)])\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "# ================ TTT ================\n",
    "ttt_cfg = DEFAULT_ESM2_35M_TTT_CFG\n",
    "model = ESM2TTT.ttt_from_pretrained(model, ttt_cfg)\n",
    "model.ttt(seq)\n",
    "# =====================================\n",
    "\n",
    "# Extract per-residue representations\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[12])\n",
    "token_representations = results[\"representations\"][12]\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "print(sequence_representations[0].shape)\n",
    "\n",
    "# Reset model to original state (after this model.ttt can be called again on another protein)\n",
    "# ================ TTT ================\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESMFold\n",
    "\n",
    "Adaptation of an official [ESMFold example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting protein structure. Please note that rerunning the customization multiple times or with different random seeds (`ttt_cfg.seed=<seed>`) may lead to slightly different results. So, running several times can yield a better (i.e., higher-pLDDT) solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pLDDT: 37.87921248142645\n",
      "2025-11-04 15:34:28,076 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 1.75401, plddt: 37.87921\n",
      "2025-11-04 15:34:30,745 | INFO | step: 1, accumulated_step: 4, loss: 2.51367, perplexity: None, ttt_step_time: 0.59175, score_seq_time: 0.00000, eval_step_time: 1.75558, plddt: 54.04266\n",
      "2025-11-04 15:34:33,507 | INFO | step: 2, accumulated_step: 8, loss: 2.60938, perplexity: None, ttt_step_time: 0.55520, score_seq_time: 0.00000, eval_step_time: 1.74990, plddt: 77.62975\n",
      "2025-11-04 15:34:35,813 | INFO | step: 3, accumulated_step: 12, loss: 2.50000, perplexity: None, ttt_step_time: 0.55554, score_seq_time: 0.00000, eval_step_time: 1.74906, plddt: 72.34952\n",
      "2025-11-04 15:34:38,393 | INFO | step: 4, accumulated_step: 16, loss: 2.12109, perplexity: None, ttt_step_time: 0.55375, score_seq_time: 0.00000, eval_step_time: 1.74888, plddt: 78.22857\n",
      "2025-11-04 15:34:40,699 | INFO | step: 5, accumulated_step: 20, loss: 2.21289, perplexity: None, ttt_step_time: 0.55542, score_seq_time: 0.00000, eval_step_time: 1.74909, plddt: 74.24552\n",
      "2025-11-04 15:34:43,003 | INFO | step: 6, accumulated_step: 24, loss: 2.12500, perplexity: None, ttt_step_time: 0.55390, score_seq_time: 0.00000, eval_step_time: 1.74969, plddt: 66.52922\n",
      "2025-11-04 15:34:45,307 | INFO | step: 7, accumulated_step: 28, loss: 1.53516, perplexity: None, ttt_step_time: 0.55428, score_seq_time: 0.00000, eval_step_time: 1.74883, plddt: 70.01627\n",
      "2025-11-04 15:34:47,611 | INFO | step: 8, accumulated_step: 32, loss: 1.26855, perplexity: None, ttt_step_time: 0.55372, score_seq_time: 0.00000, eval_step_time: 1.74948, plddt: 39.23634\n",
      "2025-11-04 15:34:49,914 | INFO | step: 9, accumulated_step: 36, loss: 1.59863, perplexity: None, ttt_step_time: 0.55375, score_seq_time: 0.00000, eval_step_time: 1.74853, plddt: 69.29087\n",
      "2025-11-04 15:34:52,219 | INFO | step: 10, accumulated_step: 40, loss: 0.87549, perplexity: None, ttt_step_time: 0.55437, score_seq_time: 0.00000, eval_step_time: 1.74940, plddt: 43.31865\n",
      "pLDDT: 78.22857355126301\n"
     ]
    }
   ],
   "source": [
    "# Set your sequence\n",
    "sequence = \"GIHLGELGLLPSTVLAIGYFENLVNIICESLNMLPKLEVSGKEYKKFKFTIVIPKDLDANIKKRAKIYFKQKSLIEIEIPTSSRNYPIHIQFDENSTDDILHLYDMPTTIGGIDKAIEMFMRKGHIGKTDQQKLLEERELRNFKTTLENLIATDAFAKEMVEVIIEE\"\n",
    "\n",
    "# Load model\n",
    "model = esm.pretrained.esmfold_v1()\n",
    "model = model.eval().cuda()\n",
    "\n",
    "def predict_structure(model, sequence):\n",
    "    with torch.no_grad():\n",
    "        output = model.infer_pdb(sequence)\n",
    "\n",
    "    with open(\"result.pdb\", \"w\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
    "    print('pLDDT:', struct.b_factor.mean())\n",
    "\n",
    "predict_structure(model, sequence)\n",
    "\n",
    "# ============ ProteinTTT =============\n",
    "ttt_cfg = DEFAULT_ESMFOLD_TTT_CFG\n",
    "ttt_cfg.steps = 10  # This is how you can modify the config\n",
    "ttt_cfg.seed = 5\n",
    "model = ESMFoldTTT.ttt_from_pretrained(model, ttt_cfg=ttt_cfg, esmfold_config=model.cfg)\n",
    "model.ttt(sequence)\n",
    "# =====================================\n",
    "\n",
    "predict_structure(model, sequence)\n",
    "\n",
    "# Reset model to original state (after this model.ttt can be called again on another protein)\n",
    "# ============== ProteinTTT ===========\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProGen2\n",
    "Example for an autoregressive model\n",
    "\n",
    "https://www.cell.com/cell-systems/fulltext/S2405-4712(23)00272-7\n",
    "\n",
    "Conda environment should be installed following https://github.com/salesforce/progen/blob/main/progen2/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001bc\u001b[3J--2025-11-28 17:08:26--  https://storage.googleapis.com/sfr-progen-research/checkpoints/progen2-small.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.36.123, 142.251.36.91, 142.251.38.155, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.36.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 561673660 (536M) [application/x-tar]\n",
      "Saving to: â€˜checkpoints/progen2-small/progen2-small.tar.gz.2â€™\n",
      "\n",
      "progen2-small.tar.g 100%[===================>] 535.65M  11.7MB/s    in 44s     \n",
      "\n",
      "2025-11-28 17:09:11 (12.2 MB/s) - â€˜checkpoints/progen2-small/progen2-small.tar.gz.2â€™ saved [561673660/561673660]\n",
      "\n",
      "x ./\n",
      "x ./config.json\n",
      "x ./pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Download ProGen2 code and weights\n",
    "!git clone https://github.com/salesforce/progen ../proteinttt/models && \\\n",
    "    cd ../proteinttt/models/progen/progen2 && \\\n",
    "    set model progen2-small && \\\n",
    "    wget -P checkpoints/$model https://storage.googleapis.com/sfr-progen-research/checkpoints/$model.tar.gz && \\\n",
    "    tar -xvf checkpoints/$model/$model.tar.gz -C checkpoints/$model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProGenForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "ProGenForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "ProGenForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "ProGenForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "ProGen2TTT has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 17:13:55,565 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:13:56,941 | INFO | step: 1, accumulated_step: 4, loss: 2.81965, perplexity: None, ttt_step_time: 1.37571, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:13:58,399 | INFO | step: 2, accumulated_step: 8, loss: 2.82224, perplexity: None, ttt_step_time: 1.45787, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:13:59,907 | INFO | step: 3, accumulated_step: 12, loss: 2.98479, perplexity: None, ttt_step_time: 1.50796, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:01,341 | INFO | step: 4, accumulated_step: 16, loss: 2.97238, perplexity: None, ttt_step_time: 1.43282, score_seq_time: 0.00000, eval_step_time: 0.00001\n",
      "2025-11-28 17:14:02,829 | INFO | step: 5, accumulated_step: 20, loss: 3.36476, perplexity: None, ttt_step_time: 1.48732, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:04,348 | INFO | step: 6, accumulated_step: 24, loss: 2.99391, perplexity: None, ttt_step_time: 1.51833, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:05,828 | INFO | step: 7, accumulated_step: 28, loss: 2.91841, perplexity: None, ttt_step_time: 1.47943, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:07,316 | INFO | step: 8, accumulated_step: 32, loss: 2.97866, perplexity: None, ttt_step_time: 1.48823, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:08,757 | INFO | step: 9, accumulated_step: 36, loss: 2.67594, perplexity: None, ttt_step_time: 1.43968, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:10,357 | INFO | step: 10, accumulated_step: 40, loss: 2.37101, perplexity: None, ttt_step_time: 1.60000, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:11,899 | INFO | step: 11, accumulated_step: 44, loss: 2.02399, perplexity: None, ttt_step_time: 1.54196, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:13,349 | INFO | step: 12, accumulated_step: 48, loss: 1.85888, perplexity: None, ttt_step_time: 1.44879, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:14,899 | INFO | step: 13, accumulated_step: 52, loss: 2.61724, perplexity: None, ttt_step_time: 1.54998, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:16,425 | INFO | step: 14, accumulated_step: 56, loss: 1.53790, perplexity: None, ttt_step_time: 1.52508, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-11-28 17:14:18,002 | INFO | step: 15, accumulated_step: 60, loss: 1.06972, perplexity: None, ttt_step_time: 1.57680, score_seq_time: 0.00000, eval_step_time: 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ttt_step_data': defaultdict(dict,\n",
       "             {0: {'eval_step_preds': {}},\n",
       "              1: {'eval_step_preds': {}},\n",
       "              2: {'eval_step_preds': {}},\n",
       "              3: {'eval_step_preds': {}},\n",
       "              4: {'eval_step_preds': {}},\n",
       "              5: {'eval_step_preds': {}},\n",
       "              6: {'eval_step_preds': {}},\n",
       "              7: {'eval_step_preds': {}},\n",
       "              8: {'eval_step_preds': {}},\n",
       "              9: {'eval_step_preds': {}},\n",
       "              10: {'eval_step_preds': {}},\n",
       "              11: {'eval_step_preds': {}},\n",
       "              12: {'eval_step_preds': {}},\n",
       "              13: {'eval_step_preds': {}},\n",
       "              14: {'eval_step_preds': {}},\n",
       "              15: {'eval_step_preds': {}}}),\n",
       " 'df':     step  accumulated_step      loss perplexity  ttt_step_time  \\\n",
       " 0      0                 0       NaN       None       0.000000   \n",
       " 1      1                 4  2.819646       None       1.375708   \n",
       " 2      2                 8  2.822244       None       1.457869   \n",
       " 3      3                12  2.984790       None       1.507962   \n",
       " 4      4                16  2.972377       None       1.432822   \n",
       " 5      5                20  3.364765       None       1.487320   \n",
       " 6      6                24  2.993915       None       1.518329   \n",
       " 7      7                28  2.918411       None       1.479432   \n",
       " 8      8                32  2.978659       None       1.488231   \n",
       " 9      9                36  2.675945       None       1.439684   \n",
       " 10    10                40  2.371013       None       1.600003   \n",
       " 11    11                44  2.023987       None       1.541956   \n",
       " 12    12                48  1.858883       None       1.448789   \n",
       " 13    13                52  2.617240       None       1.549977   \n",
       " 14    14                56  1.537904       None       1.525081   \n",
       " 15    15                60  1.069715       None       1.576798   \n",
       " \n",
       "     score_seq_time  eval_step_time  \n",
       " 0              0.0        0.000002  \n",
       " 1              0.0        0.000004  \n",
       " 2              0.0        0.000004  \n",
       " 3              0.0        0.000003  \n",
       " 4              0.0        0.000005  \n",
       " 5              0.0        0.000004  \n",
       " 6              0.0        0.000003  \n",
       " 7              0.0        0.000004  \n",
       " 8              0.0        0.000004  \n",
       " 9              0.0        0.000003  \n",
       " 10             0.0        0.000004  \n",
       " 11             0.0        0.000004  \n",
       " 12             0.0        0.000004  \n",
       " 13             0.0        0.000004  \n",
       " 14             0.0        0.000004  \n",
       " 15             0.0        0.000003  }"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from proteinttt.models.progen2 import ProGen2TTT\n",
    "from tokenizers import Tokenizer\n",
    "from proteinttt.models.progen.progen2.models.progen.modeling_progen import ProGenForCausalLM\n",
    "\n",
    "sequence = \"GIHLGELGLLPSTVLAIGYFENLVNIICESLNMLPKLEVSGKEYKKFKFTIVIPKDLDANIKKRAKIYFKQKSLIEIEIPTSSRNYPIHIQFDENSTDDILHLYDMPTTIGGIDKAIEMFMRKGHIGKTDQQKLLEERELRNFKTTLENLIATDAFAKEMVEVIIEE\"\n",
    "ckpts_dir = \"../proteinttt/models/progen/progen2/checkpoints/\"\n",
    "model_name = \"progen2-small\"\n",
    "\n",
    "with open(ckpts_dir + \"tokenizer.json\", \"r\") as f:\n",
    "    tokenizer = Tokenizer.from_str(f.read())\n",
    "\n",
    "model = ProGenForCausalLM.from_pretrained(ckpts_dir + model_name)\n",
    "model = ProGen2TTT.ttt_from_pretrained(model=model, tokenizer=tokenizer, config=model.config)\n",
    "\n",
    "model.ttt(sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progen2_ttt310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
