{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/lightning_lite/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "import biotite.structure.io as bsio\n",
    "\n",
    "from proteinttt.models.esm2 import ESM2TTT, DEFAULT_ESM2_35M_TTT_CFG\n",
    "from proteinttt.models.esmfold import ESMFoldTTT, DEFAULT_ESMFOLD_TTT_CFG\n",
    "from proteinttt.base import TTTConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESM2\n",
    "\n",
    "Adaptation of an official [ESM2 example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project/open-35-8/antonb/miniconda3/envs/esmfold/lib/python3.10/site-packages/torch/hub.py:338: UserWarning: TORCH_HUB is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_HUB is deprecated, please use env TORCH_HOME instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 15:33:14,661 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 0.00001\n",
      "2025-11-04 15:33:15,400 | INFO | step: 1, accumulated_step: 16, loss: 0.75260, perplexity: None, ttt_step_time: 0.73787, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:15,831 | INFO | step: 2, accumulated_step: 32, loss: 0.73837, perplexity: None, ttt_step_time: 0.43010, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:16,262 | INFO | step: 3, accumulated_step: 48, loss: 0.68426, perplexity: None, ttt_step_time: 0.43029, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:16,692 | INFO | step: 4, accumulated_step: 64, loss: 0.69365, perplexity: None, ttt_step_time: 0.42923, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,117 | INFO | step: 5, accumulated_step: 80, loss: 0.67766, perplexity: None, ttt_step_time: 0.42461, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,520 | INFO | step: 6, accumulated_step: 96, loss: 0.70075, perplexity: None, ttt_step_time: 0.40306, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:17,923 | INFO | step: 7, accumulated_step: 112, loss: 0.65884, perplexity: None, ttt_step_time: 0.40221, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:18,326 | INFO | step: 8, accumulated_step: 128, loss: 0.66001, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:18,729 | INFO | step: 9, accumulated_step: 144, loss: 0.64459, perplexity: None, ttt_step_time: 0.40210, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,131 | INFO | step: 10, accumulated_step: 160, loss: 0.64300, perplexity: None, ttt_step_time: 0.40212, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,534 | INFO | step: 11, accumulated_step: 176, loss: 0.63965, perplexity: None, ttt_step_time: 0.40232, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:19,937 | INFO | step: 12, accumulated_step: 192, loss: 0.58372, perplexity: None, ttt_step_time: 0.40196, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:20,340 | INFO | step: 13, accumulated_step: 208, loss: 0.61558, perplexity: None, ttt_step_time: 0.40238, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:20,742 | INFO | step: 14, accumulated_step: 224, loss: 0.61332, perplexity: None, ttt_step_time: 0.40196, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,145 | INFO | step: 15, accumulated_step: 240, loss: 0.60931, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,548 | INFO | step: 16, accumulated_step: 256, loss: 0.63115, perplexity: None, ttt_step_time: 0.40213, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:21,950 | INFO | step: 17, accumulated_step: 272, loss: 0.56141, perplexity: None, ttt_step_time: 0.40182, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:22,353 | INFO | step: 18, accumulated_step: 288, loss: 0.56737, perplexity: None, ttt_step_time: 0.40264, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:22,756 | INFO | step: 19, accumulated_step: 304, loss: 0.59121, perplexity: None, ttt_step_time: 0.40208, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,159 | INFO | step: 20, accumulated_step: 320, loss: 0.54132, perplexity: None, ttt_step_time: 0.40199, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,562 | INFO | step: 21, accumulated_step: 336, loss: 0.52530, perplexity: None, ttt_step_time: 0.40292, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:23,966 | INFO | step: 22, accumulated_step: 352, loss: 0.56913, perplexity: None, ttt_step_time: 0.40299, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:24,368 | INFO | step: 23, accumulated_step: 368, loss: 0.49984, perplexity: None, ttt_step_time: 0.40215, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:24,771 | INFO | step: 24, accumulated_step: 384, loss: 0.52193, perplexity: None, ttt_step_time: 0.40208, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,174 | INFO | step: 25, accumulated_step: 400, loss: 0.50582, perplexity: None, ttt_step_time: 0.40207, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,577 | INFO | step: 26, accumulated_step: 416, loss: 0.51759, perplexity: None, ttt_step_time: 0.40236, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:25,979 | INFO | step: 27, accumulated_step: 432, loss: 0.50721, perplexity: None, ttt_step_time: 0.40210, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:26,382 | INFO | step: 28, accumulated_step: 448, loss: 0.48393, perplexity: None, ttt_step_time: 0.40220, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-11-04 15:33:26,785 | INFO | step: 29, accumulated_step: 464, loss: 0.50045, perplexity: None, ttt_step_time: 0.40203, score_seq_time: 0.00000, eval_step_time: 0.00006\n",
      "2025-11-04 15:33:27,187 | INFO | step: 30, accumulated_step: 480, loss: 0.50168, perplexity: None, ttt_step_time: 0.40222, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "torch.Size([480])\n"
     ]
    }
   ],
   "source": [
    "seq = \"HRQALGERLYPRVQAMQPAFASKITGMLLELSPAQLLLLLASEDSLRARVDEAMELII\"\n",
    "\n",
    "# Load ESM-2 model and data\n",
    "model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval().to(device)  # disables dropout for deterministic results\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter([(None, seq)])\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "# ================ TTT ================\n",
    "ttt_cfg = DEFAULT_ESM2_35M_TTT_CFG\n",
    "model = ESM2TTT.ttt_from_pretrained(model, ttt_cfg)\n",
    "model.ttt(seq)\n",
    "# =====================================\n",
    "\n",
    "# Extract per-residue representations\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[12])\n",
    "token_representations = results[\"representations\"][12]\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "print(sequence_representations[0].shape)\n",
    "\n",
    "# Reset model to original state (after this model.ttt can be called again on another protein)\n",
    "# ================ TTT ================\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESMFold\n",
    "\n",
    "Adaptation of an official [ESMFold example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting protein structure. Please note that rerunning the customization multiple times or with different random seeds (`ttt_cfg.seed=<seed>`) may lead to slightly different results. So, running several times can yield a better (i.e., higher-pLDDT) solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pLDDT: 37.87921248142645\n",
      "2025-11-04 15:34:28,076 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 1.75401, plddt: 37.87921\n",
      "2025-11-04 15:34:30,745 | INFO | step: 1, accumulated_step: 4, loss: 2.51367, perplexity: None, ttt_step_time: 0.59175, score_seq_time: 0.00000, eval_step_time: 1.75558, plddt: 54.04266\n",
      "2025-11-04 15:34:33,507 | INFO | step: 2, accumulated_step: 8, loss: 2.60938, perplexity: None, ttt_step_time: 0.55520, score_seq_time: 0.00000, eval_step_time: 1.74990, plddt: 77.62975\n",
      "2025-11-04 15:34:35,813 | INFO | step: 3, accumulated_step: 12, loss: 2.50000, perplexity: None, ttt_step_time: 0.55554, score_seq_time: 0.00000, eval_step_time: 1.74906, plddt: 72.34952\n",
      "2025-11-04 15:34:38,393 | INFO | step: 4, accumulated_step: 16, loss: 2.12109, perplexity: None, ttt_step_time: 0.55375, score_seq_time: 0.00000, eval_step_time: 1.74888, plddt: 78.22857\n",
      "2025-11-04 15:34:40,699 | INFO | step: 5, accumulated_step: 20, loss: 2.21289, perplexity: None, ttt_step_time: 0.55542, score_seq_time: 0.00000, eval_step_time: 1.74909, plddt: 74.24552\n",
      "2025-11-04 15:34:43,003 | INFO | step: 6, accumulated_step: 24, loss: 2.12500, perplexity: None, ttt_step_time: 0.55390, score_seq_time: 0.00000, eval_step_time: 1.74969, plddt: 66.52922\n",
      "2025-11-04 15:34:45,307 | INFO | step: 7, accumulated_step: 28, loss: 1.53516, perplexity: None, ttt_step_time: 0.55428, score_seq_time: 0.00000, eval_step_time: 1.74883, plddt: 70.01627\n",
      "2025-11-04 15:34:47,611 | INFO | step: 8, accumulated_step: 32, loss: 1.26855, perplexity: None, ttt_step_time: 0.55372, score_seq_time: 0.00000, eval_step_time: 1.74948, plddt: 39.23634\n",
      "2025-11-04 15:34:49,914 | INFO | step: 9, accumulated_step: 36, loss: 1.59863, perplexity: None, ttt_step_time: 0.55375, score_seq_time: 0.00000, eval_step_time: 1.74853, plddt: 69.29087\n",
      "2025-11-04 15:34:52,219 | INFO | step: 10, accumulated_step: 40, loss: 0.87549, perplexity: None, ttt_step_time: 0.55437, score_seq_time: 0.00000, eval_step_time: 1.74940, plddt: 43.31865\n",
      "pLDDT: 78.22857355126301\n"
     ]
    }
   ],
   "source": [
    "# Set your sequence\n",
    "sequence = \"GIHLGELGLLPSTVLAIGYFENLVNIICESLNMLPKLEVSGKEYKKFKFTIVIPKDLDANIKKRAKIYFKQKSLIEIEIPTSSRNYPIHIQFDENSTDDILHLYDMPTTIGGIDKAIEMFMRKGHIGKTDQQKLLEERELRNFKTTLENLIATDAFAKEMVEVIIEE\"\n",
    "\n",
    "# Load model\n",
    "model = esm.pretrained.esmfold_v1()\n",
    "model = model.eval().cuda()\n",
    "\n",
    "def predict_structure(model, sequence):\n",
    "    with torch.no_grad():\n",
    "        output = model.infer_pdb(sequence)\n",
    "\n",
    "    with open(\"result.pdb\", \"w\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
    "    print('pLDDT:', struct.b_factor.mean())\n",
    "\n",
    "predict_structure(model, sequence)\n",
    "\n",
    "# ============ ProteinTTT =============\n",
    "ttt_cfg = DEFAULT_ESMFOLD_TTT_CFG\n",
    "ttt_cfg.steps = 10  # This is how you can modify the config\n",
    "ttt_cfg.seed = 5\n",
    "model = ESMFoldTTT.ttt_from_pretrained(model, ttt_cfg=ttt_cfg, esmfold_config=model.cfg)\n",
    "model.ttt(sequence)\n",
    "# =====================================\n",
    "\n",
    "predict_structure(model, sequence)\n",
    "\n",
    "# Reset model to original state (after this model.ttt can be called again on another protein)\n",
    "# ============== ProteinTTT ===========\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
